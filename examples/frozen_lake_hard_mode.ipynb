{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import pathlib \n",
    "path = pathlib.Path(os.getcwd())\n",
    "module_path = str(path.parent) + '/'\n",
    "sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymdp import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\"\"\"Automated context switching\"\"\"\n",
    "\n",
    "map_context_1 = [\n",
    "    'SFFFF',\n",
    "    'FFFFF',\n",
    "    'FFFHF',\n",
    "    'FFGFF',\n",
    "    'FFFFF']\n",
    "\n",
    "map_context_2 = [\n",
    "    'SFFFF',\n",
    "    'FFFFF',\n",
    "    'FFFGF',\n",
    "    'FFHFF',\n",
    "    'FFFFF']\n",
    "\n",
    "map_context_1 = np.array([list(row) for row in map_context_1])\n",
    "\n",
    "map_context_2 = np.array([list(row) for row in map_context_2])\n",
    "grid_width = 5\n",
    "grid_height = 5\n",
    "\n",
    "def plot_grid(grid_width, grid_height, position = 0):\n",
    "\n",
    "    grid = np.zeros((grid_width, grid_height))\n",
    "\n",
    "    # grid[1,2] = 1\n",
    "    # grid[2,1] = -1\n",
    "    def set_grid(loc, val):\n",
    "        grid[math.floor(loc / 5), math.floor(loc % 5)] += val\n",
    "    \n",
    "    for loc in range(25):\n",
    "        set_grid(loc, 2)   \n",
    "    \n",
    "\n",
    "    # Plotting the array with each grid labeled with integers, indexed at 0 (without the colorbar)\n",
    "    fig, ax = plt.subplots(figsize = (2,2))\n",
    "    cax = ax.matshow(grid, cmap='viridis')\n",
    "\n",
    "    idx = 0\n",
    "    # Labeling each cell with the corresponding integer, adjusted for zero-indexing\n",
    "    for (i, j), val in np.ndenumerate(map_context_1):\n",
    "        ax.text(j, i, str(val ), ha='center', va='center', color='white')\n",
    "        if idx == position:\n",
    "            ax.text(j, i, \"A\", ha='center', va='center', color='red')\n",
    "        idx +=1\n",
    "    plt.show()\n",
    "\n",
    "plot_grid(grid_width, grid_height, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_location_states: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)]\n",
      " Length of grid_location_states: 25\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create variables for the storing the dimensionalities of the hidden states and the observations \"\"\"\n",
    "import itertools\n",
    "\n",
    "#HIDDEN STATES\n",
    "\"\"\" Create  the grid locations in the form of a list of (Y, X) tuples -- HINT: use itertools \"\"\"\n",
    "grid_location_states = list(itertools.product(range(grid_width), range(grid_height))) #hidden state\n",
    "context_names = ['Goal-18', 'Goal-14'] #context 0 and context 1\n",
    "\n",
    "print(f\"grid_location_states: {grid_location_states}\")\n",
    "print(f\" Length of grid_location_states: {len(grid_location_states)}\")\n",
    "\n",
    "\"\"\" Define `num_states` and `num_factors` below \"\"\"\n",
    "num_states = [len(grid_location_states), len(context_names)] #[25,2]\n",
    "num_state_factors = len(num_states) #2 hidden state factors\n",
    "\n",
    "location_action_names = [\"UP\", \"RIGHT\", \"DOWN\", \"LEFT\"] #, \"STAY\"]\n",
    "\n",
    "context_action_names = [\"Do-nothing\"]\n",
    "\"\"\" Define `num_controls` below \"\"\"\n",
    "num_controls = [len(location_action_names), len(context_action_names)] #num of actions\n",
    "\n",
    "#OBSERVATIONS\n",
    "grid_location_obs = list(itertools.product(range(grid_width), range(grid_height)))\n",
    "score_obs = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "\"\"\" Define `num_obs` and `num_modalities` below \"\"\"\n",
    "num_obs = [len(grid_location_obs), len(score_obs)] # [25, 3]\n",
    "num_modalities = len(num_obs) #2 observation modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.98, 0.98],\n",
       "        [0.01, 0.01],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       [[0.01, 0.01],\n",
       "        [0.97, 0.97],\n",
       "        [0.01, 0.01],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.01, 0.01],\n",
       "        [0.97, 0.97],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.97, 0.97],\n",
       "        [0.01, 0.01],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.01, 0.01],\n",
       "        [0.97, 0.97],\n",
       "        [0.01, 0.01]],\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.01, 0.01],\n",
       "        [0.98, 0.98]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Generate the A array \"\"\"\n",
    "A = utils.obj_array( num_modalities )\n",
    "\n",
    "def get_neighbors(i):\n",
    "    ns = []\n",
    "    if i >5:\n",
    "        ns.append(i-5)\n",
    "    if i < 20:\n",
    "        ns.append(i+5)\n",
    "    if i % 5 != 0:\n",
    "        ns.append(i-1)\n",
    "    if (i+1)% 5 != 0:\n",
    "        ns.append(i+1)\n",
    "    return ns\n",
    "    \n",
    "A_location = np.zeros((len(grid_location_obs), len(grid_location_states), len(context_names))) #[observation modality, SF1, SF2]\n",
    "\n",
    "for i in range(len(context_names)):\n",
    "    A_location[:,:,i] = np.zeros((len(grid_location_obs), len(grid_location_states)))\n",
    "    for j in range(len(grid_location_obs)):\n",
    "        ns = get_neighbors(j)\n",
    "        A_location[j,j,i] = 1.0 - len(ns) * .01\n",
    "        for n in ns:\n",
    "            A_location[j,n,i] = .01\n",
    "\n",
    "A[0] = A_location\n",
    "\n",
    "\n",
    "A_score = np.zeros((len(score_obs), len(grid_location_states), len(context_names))) #[observation modality, SF1, SF2]\n",
    "\n",
    "#for first context (Pos, Neg, Neutral)\n",
    "A_score[:,:,0] = np.array([[0,0,1]] * 25).T #\n",
    "A_score[:,17,0] = [1,0,0]\n",
    "A_score[:,13,0] = [0,1,0]\n",
    "\n",
    "#for second context\n",
    "A_score[:,:,1] = np.array([[0,0,1]] * 25).T\n",
    "A_score[:,13,1] = [1,0,0]\n",
    "A_score[:,17,1] = [0,1,0]\n",
    "\n",
    "A[1] = A_score\n",
    "\n",
    "A_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we need to hardcode absorbing latent states in G and H?\n",
    "\n",
    "#Initialize overall B\n",
    "\n",
    "B = utils.obj_array(len(num_states))\n",
    "\n",
    "#B[0]: State Factor 1: Location\n",
    "#9x9x4: [len(location), len(location), len(actions)]\n",
    "#depends on movement\n",
    "\n",
    "#location_action_names = [\"UP\", \"RIGHT\", \"DOWN\", \"LEFT\"] #, \"STAY\"]\n",
    "\n",
    "B_grid_movement = np.zeros((len(grid_location_states), len(grid_location_states), len(location_action_names))) #[observation modality, SF1, SF2]\n",
    "def set_with_convolution(i):\n",
    "    up_new_position = i - 5 if i >= 5 else i\n",
    "    up_v = 0\n",
    "    if up_new_position >= 5:\n",
    "        up_v = .1\n",
    "        B_grid_movement[up_new_position-5,i,0] = up_v\n",
    "    B_grid_movement[up_new_position,i,0] = 1 - up_v\n",
    "\n",
    "    down_new_position = i + 5 if i < 20 else i\n",
    "    down_v = 0\n",
    "    if down_new_position < 20:\n",
    "        down_v = .01\n",
    "        B_grid_movement[down_new_position+5,i,2] = down_v\n",
    "    B_grid_movement[down_new_position,i,2] = 1 - down_v\n",
    "\n",
    "    left_new_position = i if i % 5 == 0 else i - 1\n",
    "    left_v = 0\n",
    "    if left_new_position % 5 > 0:\n",
    "        left_v = .01\n",
    "        B_grid_movement[left_new_position-1,i,3] = left_v\n",
    "    B_grid_movement[left_new_position,i,3] = 1 - left_v\n",
    "\n",
    "    right_new_position = i if i % 5 == 4 else i - 1\n",
    "    right_v = 0\n",
    "    if right_new_position % 5 < 4:\n",
    "        right_v = .01\n",
    "        B_grid_movement[right_new_position+1,i,1] = right_v\n",
    "    B_grid_movement[right_new_position,i,1] = 1 - right_v\n",
    "    \n",
    "for i in range(25): #initial state i\n",
    "    B_grid_movement[:,i,0] = np.zeros(25)\n",
    "    B_grid_movement[:,i,1] = np.zeros(25)\n",
    "    B_grid_movement[:,i,2] = np.zeros(25)\n",
    "    B_grid_movement[:,i,3] = np.zeros(25)\n",
    "    set_with_convolution(i)\n",
    "    # up_new_position = i - 5 if i >= 5 else i\n",
    "    # B_grid_movement[up_new_position,i,0] = 1\n",
    "    # down_new_position = i + 5 if i < 20 else i\n",
    "    # B_grid_movement[down_new_position,i,2] = 1\n",
    "    # left_new_position = i if (i) % 5 == 0 else i - 1\n",
    "    # B_grid_movement[left_new_position,i,3] = 1\n",
    "    # right_new_position = i if (i + 1) % 5 == 0 else i + 1\n",
    "    # B_grid_movement[right_new_position,i,1] = 1\n",
    "\n",
    "B[0] = B_grid_movement\n",
    "\n",
    "B_context = np.zeros((len(context_names), len(context_names), len(context_action_names)))\n",
    "\n",
    "B_context[:,:,0] = np.eye(len(context_names))\n",
    "\n",
    "B[1] = B_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0][:,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall C\n",
    "C = utils.obj_array( num_modalities )\n",
    "\n",
    "#Preference over Observation Modality 1: Grid Locations [-4, 0, ... 0]\n",
    "C_location = np.zeros(25)\n",
    "C_location[0] = -4 #we prefer to not stay in the starting location\n",
    "C[0] = C_location\n",
    "\n",
    "#Preference over Observation Modality 2: Scores [-4, 4, 0]\n",
    "C[1] = np.array([4, -4, 0]) #we prefer the goal state, we negatively prefer the hole state, and are neutral else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall D\n",
    "D = utils.obj_array( num_state_factors )\n",
    "\n",
    "#Prior over State Factor 1: Grid Locations: [1,0,0,0,0,0,0,0,0]\n",
    "D_location = np.zeros(25)\n",
    "D_location[0] = 1 # we have prior knowledge that our starting location is in position 1\n",
    "D[0] = D_location\n",
    "\n",
    "#Prior over State Factor 2: Context: Uniform [.5 .5]\n",
    "D[1] = np.array([.5, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_modalities_and_states = utils.obj_array(num_modalities)\n",
    "zeta_modalities_and_states[0] = np.random.uniform(0,1,size = (num_states[0], num_states[1]))\n",
    "zeta_modalities_and_states[1] = np.random.uniform(0,1,size = (num_states[0], num_states[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0].shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_modalities_and_states = utils.obj_array(2)\n",
    "omega_modalities_and_states[0] = np.random.uniform(0,1,size = B[0].shape[1:])\n",
    "omega_modalities_and_states[1] = np.random.uniform(0,1,size = B[1].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp import agent\n",
    "policy_len = 6\n",
    "agent_zeta_omega = agent.Agent(A = A, B = B, C = C, D = D, policy_len = policy_len, beta_omega_prior = omega_modalities_and_states, beta_zeta_prior = zeta_modalities_and_states) #policy length = number of actions in policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_modalities_and_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_zeta_omega.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_zeta_omega.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary function that takes in agent and outputs score ... Environment step function will have two step\n",
    "def score_from_location(location):\n",
    "  if location == 7:\n",
    "    score = 0\n",
    "\n",
    "  elif location == 5:\n",
    "    score = 1\n",
    "\n",
    "  else:\n",
    "    score = 2\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary function that takes in agent and outputs score ... Environment step function will have two step\n",
    "def score_from_location(location):\n",
    "  if location == 7:\n",
    "    score = 0\n",
    "\n",
    "  elif location == 5:\n",
    "    score = 1\n",
    "\n",
    "  else:\n",
    "    score = 2\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP: 0\n",
      "observation: [0, 2]\n",
      "inferred state: 0\n",
      "inferred policies\n",
      "next_action: RIGHT\n",
      "location_observation: 1\n",
      "score_observation: 2\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m plot_grid(grid_width, grid_height, location_observation)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# if t > 0:\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m agent\u001b[38;5;241m.\u001b[39mbeta_omega, agent\u001b[38;5;241m.\u001b[39mbeta_omega_prior \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_omega\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m agent\u001b[38;5;241m.\u001b[39mbeta_zeta, agent\u001b[38;5;241m.\u001b[39mbeta_zeta_prior \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mupdate_zeta(observation)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOmega means: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(agent\u001b[38;5;241m.\u001b[39mbeta_omega[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(agent\u001b[38;5;241m.\u001b[39mbeta_omega[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/pymdp/pymdp/agent.py:901\u001b[0m, in \u001b[0;36mAgent.update_omega\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_omega\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega_prior \u001b[38;5;241m=\u001b[39m \u001b[43mlearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_beta_omega\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqs_pi_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqs_pi_policy_previous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta_omega\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta_omega_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB_factor_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_prior\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_omega_prior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mscale_B_with_omega(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega)\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega_prior\n",
      "File \u001b[0;32m~/code/pymdp/pymdp/learning.py:554\u001b[0m, in \u001b[0;36mupdate_beta_omega\u001b[0;34m(q_pi, qs_pi, qs_pi_previous, B, beta_omega, beta_omega_prior, policies, B_factor_list, update_prior)\u001b[0m\n\u001b[1;32m    549\u001b[0m omega_per_policy_and_time_horizon \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(policy))\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(policy)): \u001b[38;5;66;03m#iterate over the time horizon of the policy\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \n\u001b[1;32m    553\u001b[0m     \u001b[38;5;66;03m#right now i am indexing qs_pi_previous[idx][0] but for policy_len > 1 maybe we want to sum over all qs_pi_previous[idx]?\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m     qs_pi_previous_relevant_factors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_factors(qs_pi_previous[idx][t], factor_list) \u001b[38;5;28;01mfor\u001b[39;00m factor_list \u001b[38;5;129;01min\u001b[39;00m B_factor_list], dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    556\u001b[0m     omega_per_policy_and_time_horizon[t] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(B))\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(B)):\n",
      "File \u001b[0;32m~/code/pymdp/pymdp/learning.py:554\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    549\u001b[0m omega_per_policy_and_time_horizon \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(policy))\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(policy)): \u001b[38;5;66;03m#iterate over the time horizon of the policy\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \n\u001b[1;32m    553\u001b[0m     \u001b[38;5;66;03m#right now i am indexing qs_pi_previous[idx][0] but for policy_len > 1 maybe we want to sum over all qs_pi_previous[idx]?\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m     qs_pi_previous_relevant_factors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_factors(\u001b[43mqs_pi_previous\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[t], factor_list) \u001b[38;5;28;01mfor\u001b[39;00m factor_list \u001b[38;5;129;01min\u001b[39;00m B_factor_list], dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    556\u001b[0m     omega_per_policy_and_time_horizon[t] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(B))\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(B)):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#make sure whatever comes out of env is [list of indices] over observations and pass this to agent.infer_states\n",
    "from pymdp.envs.grid_worlds import GridWorldEnv\n",
    "from random import random \n",
    "\n",
    "\n",
    "env = GridWorldEnv(shape = [grid_width, grid_height], init_state=0)\n",
    "\n",
    "T = 10\n",
    "\n",
    "agent = agent_zeta_omega\n",
    "\n",
    "# agent will have perception that their location is offset slightly\n",
    "def apply_foggy_location(loc):\n",
    "    r = random()\n",
    "    if r < .25: # up\n",
    "        loc = loc - 5 if loc >= 5 else loc\n",
    "    elif r < .5: # down\n",
    "        loc = loc + 5 if loc < 19 else loc\n",
    "    elif r < .75: # left\n",
    "        loc = loc - 1 if loc % 5 != 4 else loc\n",
    "    else: # right\n",
    "        loc = loc - 1 if loc % 5 != 0 else loc\n",
    "    return loc\n",
    "\n",
    "initial_location_observation = 0\n",
    "initial_score_observation = score_from_location(initial_location_observation)\n",
    "observation = [0, 2]\n",
    "\n",
    "for t in range(T):\n",
    "    print(f\"TIMESTEP: {t}\")\n",
    "    print(f\"observation: {observation}\")\n",
    "\n",
    "    qs = agent.infer_states(observation)\n",
    "    print(f\"inferred state: {np.argmax(qs[0])}\")\n",
    "\n",
    "    q_pi, G = agent.infer_policies()\n",
    "    print(\"inferred policies\")\n",
    "    next_action = agent.sample_action()\n",
    "    next_action = int(next_action[0])\n",
    "    print(f\"next_action: {location_action_names[next_action]}\")\n",
    "    location_observation = env.step(next_action)\n",
    "    is_slippery = (t + 2) % 3 == 0\n",
    "    if is_slippery:\n",
    "        print(\"Slipping!\")\n",
    "        # replay the action to slip in the same direction\n",
    "        location_observation = env.step(next_action)\n",
    "    is_foggy = (t + 1) % 3 == 0\n",
    "    if is_foggy:\n",
    "        print(\"Fog!\")\n",
    "        location_observation = apply_foggy_location(location_observation)\n",
    "    \n",
    "    print(f\"location_observation: {location_observation}\")\n",
    "    score_observation = score_from_location(location_observation)\n",
    "    print(f\"score_observation: {score_observation}\")\n",
    "    observation = [location_observation, score_observation]\n",
    "\n",
    "    \n",
    "    plot_grid(grid_width, grid_height, location_observation)\n",
    "\n",
    "    # if t > 0:\n",
    "    agent.beta_omega, agent.beta_omega_prior = agent.update_omega()\n",
    "    agent.beta_zeta, agent.beta_zeta_prior = agent.update_zeta(observation)\n",
    "    print(f\"Omega means: {np.mean(agent.beta_omega[0])} {np.mean(agent.beta_omega[1])}\")\n",
    "    print(f\"Zeta means: {np.mean(agent.beta_zeta[0])} {np.mean(agent.beta_zeta[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.beta_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.beta_omega_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.beta_omega_prior[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.q_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
