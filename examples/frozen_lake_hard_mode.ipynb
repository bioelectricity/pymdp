{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import pathlib \n",
    "path = pathlib.Path(os.getcwd())\n",
    "module_path = str(path.parent) + '/'\n",
    "sys.path.append(module_path)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pymdp import utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\"\"\"Automated context switching\"\"\"\n",
    "\n",
    "map_context_1 = [\n",
    "    'SFFFF',\n",
    "    'FFFFF',\n",
    "    'FFFHF',\n",
    "    'FFGFF',\n",
    "    'FFFFF']\n",
    "\n",
    "map_context_2 = [\n",
    "    'SFFFF',\n",
    "    'FFFFF',\n",
    "    'FFFGF',\n",
    "    'FFHFF',\n",
    "    'FFFFF']\n",
    "\n",
    "map_context_1 = np.array([list(row) for row in map_context_1])\n",
    "\n",
    "map_context_2 = np.array([list(row) for row in map_context_2])\n",
    "grid_width = 5\n",
    "grid_height = 5\n",
    "\n",
    "def plot_grid(grid_width, grid_height, position = 0):\n",
    "\n",
    "    grid = np.zeros((grid_width, grid_height))\n",
    "\n",
    "    # grid[1,2] = 1\n",
    "    # grid[2,1] = -1\n",
    "    def set_grid(loc, val):\n",
    "        grid[math.floor(loc / 5), math.floor(loc % 5)] += val\n",
    "    \n",
    "    for loc in range(25):\n",
    "        set_grid(loc, 2)   \n",
    "    \n",
    "\n",
    "    # Plotting the array with each grid labeled with integers, indexed at 0 (without the colorbar)\n",
    "    fig, ax = plt.subplots(figsize = (2,2))\n",
    "    cax = ax.matshow(grid, cmap='viridis')\n",
    "\n",
    "    idx = 0\n",
    "    # Labeling each cell with the corresponding integer, adjusted for zero-indexing\n",
    "    for (i, j), val in np.ndenumerate(map_context_1):\n",
    "        ax.text(j, i, str(val ), ha='center', va='center', color='white')\n",
    "        if idx == position:\n",
    "            ax.text(j, i, \"A\", ha='center', va='center', color='red')\n",
    "        idx +=1\n",
    "    plt.show()\n",
    "\n",
    "plot_grid(grid_width, grid_height, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_location_states: [(0, 0), (0, 1), (0, 2), (0, 3), (0, 4), (1, 0), (1, 1), (1, 2), (1, 3), (1, 4), (2, 0), (2, 1), (2, 2), (2, 3), (2, 4), (3, 0), (3, 1), (3, 2), (3, 3), (3, 4), (4, 0), (4, 1), (4, 2), (4, 3), (4, 4)]\n",
      " Length of grid_location_states: 25\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Create variables for the storing the dimensionalities of the hidden states and the observations \"\"\"\n",
    "import itertools\n",
    "\n",
    "#HIDDEN STATES\n",
    "\"\"\" Create  the grid locations in the form of a list of (Y, X) tuples -- HINT: use itertools \"\"\"\n",
    "grid_location_states = list(itertools.product(range(grid_width), range(grid_height))) #hidden state\n",
    "context_names = ['Goal-18', 'Goal-14'] #context 0 and context 1\n",
    "\n",
    "print(f\"grid_location_states: {grid_location_states}\")\n",
    "print(f\" Length of grid_location_states: {len(grid_location_states)}\")\n",
    "\n",
    "\"\"\" Define `num_states` and `num_factors` below \"\"\"\n",
    "num_states = [len(grid_location_states), len(context_names)] #[25,2]\n",
    "num_state_factors = len(num_states) #2 hidden state factors\n",
    "\n",
    "location_action_names = [\"UP\", \"RIGHT\", \"DOWN\", \"LEFT\"] #, \"STAY\"]\n",
    "\n",
    "context_action_names = [\"Do-nothing\"]\n",
    "\"\"\" Define `num_controls` below \"\"\"\n",
    "num_controls = [len(location_action_names), len(context_action_names)] #num of actions\n",
    "\n",
    "#OBSERVATIONS\n",
    "grid_location_obs = list(itertools.product(range(grid_width), range(grid_height)))\n",
    "score_obs = [\"positive\", \"negative\", \"neutral\"]\n",
    "\n",
    "\"\"\" Define `num_obs` and `num_modalities` below \"\"\"\n",
    "num_obs = [len(grid_location_obs), len(score_obs)] # [25, 3]\n",
    "num_modalities = len(num_obs) #2 observation modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.98, 0.98],\n",
       "        [0.01, 0.01],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       [[0.01, 0.01],\n",
       "        [0.97, 0.97],\n",
       "        [0.01, 0.01],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.01, 0.01],\n",
       "        [0.97, 0.97],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.97, 0.97],\n",
       "        [0.01, 0.01],\n",
       "        [0.  , 0.  ]],\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.01, 0.01],\n",
       "        [0.97, 0.97],\n",
       "        [0.01, 0.01]],\n",
       "\n",
       "       [[0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        [0.  , 0.  ],\n",
       "        ...,\n",
       "        [0.  , 0.  ],\n",
       "        [0.01, 0.01],\n",
       "        [0.98, 0.98]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Generate the A array \"\"\"\n",
    "A = utils.obj_array( num_modalities )\n",
    "\n",
    "def get_neighbors(i):\n",
    "    ns = []\n",
    "    if i >5:\n",
    "        ns.append(i-5)\n",
    "    if i < 20:\n",
    "        ns.append(i+5)\n",
    "    if i % 5 != 0:\n",
    "        ns.append(i-1)\n",
    "    if (i+1)% 5 != 0:\n",
    "        ns.append(i+1)\n",
    "    return ns\n",
    "    \n",
    "A_location = np.zeros((len(grid_location_obs), len(grid_location_states), len(context_names))) #[observation modality, SF1, SF2]\n",
    "\n",
    "for i in range(len(context_names)):\n",
    "    A_location[:,:,i] = np.zeros((len(grid_location_obs), len(grid_location_states)))\n",
    "    for j in range(len(grid_location_obs)):\n",
    "        ns = get_neighbors(j)\n",
    "        A_location[j,j,i] = 1.0 - len(ns) * .01\n",
    "        for n in ns:\n",
    "            A_location[j,n,i] = .01\n",
    "\n",
    "A[0] = A_location\n",
    "\n",
    "\n",
    "A_score = np.zeros((len(score_obs), len(grid_location_states), len(context_names))) #[observation modality, SF1, SF2]\n",
    "\n",
    "#for first context (Pos, Neg, Neutral)\n",
    "A_score[:,:,0] = np.array([[0,0,1]] * 25).T #\n",
    "A_score[:,17,0] = [1,0,0]\n",
    "A_score[:,13,0] = [0,1,0]\n",
    "\n",
    "#for second context\n",
    "A_score[:,:,1] = np.array([[0,0,1]] * 25).T\n",
    "A_score[:,13,1] = [1,0,0]\n",
    "A_score[:,17,1] = [0,1,0]\n",
    "\n",
    "A[1] = A_score\n",
    "\n",
    "A_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do we need to hardcode absorbing latent states in G and H?\n",
    "\n",
    "#Initialize overall B\n",
    "\n",
    "B = utils.obj_array(len(num_states))\n",
    "\n",
    "#B[0]: State Factor 1: Location\n",
    "#9x9x4: [len(location), len(location), len(actions)]\n",
    "#depends on movement\n",
    "\n",
    "#location_action_names = [\"UP\", \"RIGHT\", \"DOWN\", \"LEFT\"] #, \"STAY\"]\n",
    "\n",
    "B_grid_movement = np.zeros((len(grid_location_states), len(grid_location_states), len(location_action_names))) #[observation modality, SF1, SF2]\n",
    "def set_with_convolution(i):\n",
    "    up_new_position = i - 5 if i >= 5 else i\n",
    "    up_v = 0\n",
    "    if up_new_position >= 5:\n",
    "        up_v = .1\n",
    "        B_grid_movement[up_new_position-5,i,0] = up_v\n",
    "    B_grid_movement[up_new_position,i,0] = 1 - up_v\n",
    "\n",
    "    down_new_position = i + 5 if i < 20 else i\n",
    "    down_v = 0\n",
    "    if down_new_position < 20:\n",
    "        down_v = .01\n",
    "        B_grid_movement[down_new_position+5,i,2] = down_v\n",
    "    B_grid_movement[down_new_position,i,2] = 1 - down_v\n",
    "\n",
    "    left_new_position = i if i % 5 == 0 else i - 1\n",
    "    left_v = 0\n",
    "    if left_new_position % 5 > 0:\n",
    "        left_v = .01\n",
    "        B_grid_movement[left_new_position-1,i,3] = left_v\n",
    "    B_grid_movement[left_new_position,i,3] = 1 - left_v\n",
    "\n",
    "    right_new_position = i if i % 5 == 4 else i - 1\n",
    "    right_v = 0\n",
    "    if right_new_position % 5 < 4:\n",
    "        right_v = .01\n",
    "        B_grid_movement[right_new_position+1,i,1] = right_v\n",
    "    B_grid_movement[right_new_position,i,1] = 1 - right_v\n",
    "    \n",
    "for i in range(25): #initial state i\n",
    "    B_grid_movement[:,i,0] = np.zeros(25)\n",
    "    B_grid_movement[:,i,1] = np.zeros(25)\n",
    "    B_grid_movement[:,i,2] = np.zeros(25)\n",
    "    B_grid_movement[:,i,3] = np.zeros(25)\n",
    "    set_with_convolution(i)\n",
    "    # up_new_position = i - 5 if i >= 5 else i\n",
    "    # B_grid_movement[up_new_position,i,0] = 1\n",
    "    # down_new_position = i + 5 if i < 20 else i\n",
    "    # B_grid_movement[down_new_position,i,2] = 1\n",
    "    # left_new_position = i if (i) % 5 == 0 else i - 1\n",
    "    # B_grid_movement[left_new_position,i,3] = 1\n",
    "    # right_new_position = i if (i + 1) % 5 == 0 else i + 1\n",
    "    # B_grid_movement[right_new_position,i,1] = 1\n",
    "\n",
    "B[0] = B_grid_movement\n",
    "\n",
    "B_context = np.zeros((len(context_names), len(context_names), len(context_action_names)))\n",
    "\n",
    "B_context[:,:,0] = np.eye(len(context_names))\n",
    "\n",
    "B[1] = B_context\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.99, 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  , 0.  ,\n",
       "       0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0][:,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall C\n",
    "C = utils.obj_array( num_modalities )\n",
    "\n",
    "#Preference over Observation Modality 1: Grid Locations [-4, 0, ... 0]\n",
    "C_location = np.zeros(25)\n",
    "C_location[0] = -4 #we prefer to not stay in the starting location\n",
    "C[0] = C_location\n",
    "\n",
    "#Preference over Observation Modality 2: Scores [-4, 4, 0]\n",
    "C[1] = np.array([4, -4, 0]) #we prefer the goal state, we negatively prefer the hole state, and are neutral else"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Overall D\n",
    "D = utils.obj_array( num_state_factors )\n",
    "\n",
    "#Prior over State Factor 1: Grid Locations: [1,0,0,0,0,0,0,0,0]\n",
    "D_location = np.zeros(25)\n",
    "D_location[0] = 1 # we have prior knowledge that our starting location is in position 1\n",
    "D[0] = D_location\n",
    "\n",
    "#Prior over State Factor 2: Context: Uniform [.5 .5]\n",
    "D[1] = np.array([.5, .5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_modalities_and_states = utils.obj_array(num_modalities)\n",
    "zeta_modalities_and_states[0] = np.random.uniform(0,1,size = (num_states[0], num_states[1]))\n",
    "zeta_modalities_and_states[1] = np.random.uniform(0,1,size = (num_states[0], num_states[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 4)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B[0].shape[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_modalities_and_states = utils.obj_array(2)\n",
    "omega_modalities_and_states[0] = np.random.uniform(0,1,size = B[0].shape[1:])\n",
    "omega_modalities_and_states[1] = np.random.uniform(0,1,size = B[1].shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymdp import agent\n",
    "policy_len = 6\n",
    "agent_zeta_omega = agent.Agent(A = A, B = B, C = C, D = D, policy_len = policy_len, beta_omega_prior = omega_modalities_and_states, beta_zeta_prior = zeta_modalities_and_states) #policy length = number of actions in policies\n",
    "# agent_zeta_omega = agent.Agent(A = A, B = B, C = C, D = D, policy_len = policy_len, beta_omega_prior = omega_modalities_and_states) #policy length = number of actions in policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeta_modalities_and_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_zeta_omega.B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_zeta_omega.A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "              0., 0., 0., 0., 0., 0., 0., 0.])                                   ,\n",
       "       array([0.5, 0.5])], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary function that takes in agent and outputs score ... Environment step function will have two step\n",
    "def score_from_location(location):\n",
    "  if location == 7:\n",
    "    score = 0\n",
    "\n",
    "  elif location == 5:\n",
    "    score = 1\n",
    "\n",
    "  else:\n",
    "    score = 2\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Auxiliary function that takes in agent and outputs score ... Environment step function will have two step\n",
    "def score_from_location(location):\n",
    "  if location == 7:\n",
    "    score = 0\n",
    "\n",
    "  elif location == 5:\n",
    "    score = 1\n",
    "\n",
    "  else:\n",
    "    score = 2\n",
    "\n",
    "  return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIMESTEP: 0\n",
      "observation: [0, 2]\n",
      "inferred state: 0\n",
      "inferred policies\n",
      "next_action: DOWN\n",
      "location_observation: 5\n",
      "score_observation: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[54], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m plot_grid(grid_width, grid_height, location_observation)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# if t > 0:\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m agent\u001b[38;5;241m.\u001b[39mbeta_omega, agent\u001b[38;5;241m.\u001b[39mbeta_omega_prior \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_omega\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m agent\u001b[38;5;241m.\u001b[39mbeta_zeta, agent\u001b[38;5;241m.\u001b[39mbeta_zeta_prior \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mupdate_zeta(observation)\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOmega means: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(agent\u001b[38;5;241m.\u001b[39mbeta_omega[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnp\u001b[38;5;241m.\u001b[39mmean(agent\u001b[38;5;241m.\u001b[39mbeta_omega[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/code/pymdp/pymdp/agent.py:901\u001b[0m, in \u001b[0;36mAgent.update_omega\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_omega\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 901\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega_prior \u001b[38;5;241m=\u001b[39m \u001b[43mlearning\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_beta_omega\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_pi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqs_pi_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqs_pi_policy_previous\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta_omega\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbeta_omega_prior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mB_factor_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_prior\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_omega_prior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mB \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mscale_B_with_omega(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_B, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega)\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbeta_omega_prior\n",
      "File \u001b[0;32m~/code/pymdp/pymdp/learning.py:554\u001b[0m, in \u001b[0;36mupdate_beta_omega\u001b[0;34m(q_pi, qs_pi, qs_pi_previous, B, beta_omega, beta_omega_prior, policies, B_factor_list, update_prior)\u001b[0m\n\u001b[1;32m    549\u001b[0m omega_per_policy_and_time_horizon \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(policy))\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(policy)): \u001b[38;5;66;03m#iterate over the time horizon of the policy\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \n\u001b[1;32m    553\u001b[0m     \u001b[38;5;66;03m#right now i am indexing qs_pi_previous[idx][0] but for policy_len > 1 maybe we want to sum over all qs_pi_previous[idx]?\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m     qs_pi_previous_relevant_factors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_factors(qs_pi_previous[idx][t], factor_list) \u001b[38;5;28;01mfor\u001b[39;00m factor_list \u001b[38;5;129;01min\u001b[39;00m B_factor_list], dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    556\u001b[0m     omega_per_policy_and_time_horizon[t] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(B))\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(B)):\n",
      "File \u001b[0;32m~/code/pymdp/pymdp/learning.py:554\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    549\u001b[0m omega_per_policy_and_time_horizon \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(policy))\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(policy)): \u001b[38;5;66;03m#iterate over the time horizon of the policy\u001b[39;00m\n\u001b[1;32m    552\u001b[0m \n\u001b[1;32m    553\u001b[0m     \u001b[38;5;66;03m#right now i am indexing qs_pi_previous[idx][0] but for policy_len > 1 maybe we want to sum over all qs_pi_previous[idx]?\u001b[39;00m\n\u001b[0;32m--> 554\u001b[0m     qs_pi_previous_relevant_factors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([get_factors(\u001b[43mqs_pi_previous\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m[t], factor_list) \u001b[38;5;28;01mfor\u001b[39;00m factor_list \u001b[38;5;129;01min\u001b[39;00m B_factor_list], dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    556\u001b[0m     omega_per_policy_and_time_horizon[t] \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39mobj_array(\u001b[38;5;28mlen\u001b[39m(B))\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(B)):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "#make sure whatever comes out of env is [list of indices] over observations and pass this to agent.infer_states\n",
    "from pymdp.envs.grid_worlds import GridWorldEnv\n",
    "from random import random \n",
    "\n",
    "\n",
    "env = GridWorldEnv(shape = [grid_width, grid_height], init_state=0)\n",
    "\n",
    "T = 10\n",
    "\n",
    "agent = agent_zeta_omega\n",
    "\n",
    "# agent will have perception that their location is offset slightly\n",
    "def apply_foggy_location(loc):\n",
    "    r = random()\n",
    "    if r < .25: # up\n",
    "        loc = loc - 5 if loc >= 5 else loc\n",
    "    elif r < .5: # down\n",
    "        loc = loc + 5 if loc < 19 else loc\n",
    "    elif r < .75: # left\n",
    "        loc = loc - 1 if loc % 5 != 4 else loc\n",
    "    else: # right\n",
    "        loc = loc - 1 if loc % 5 != 0 else loc\n",
    "    return loc\n",
    "\n",
    "initial_location_observation = 0\n",
    "initial_score_observation = score_from_location(initial_location_observation)\n",
    "observation = [0, 2]\n",
    "\n",
    "for t in range(T):\n",
    "    print(f\"TIMESTEP: {t}\")\n",
    "    print(f\"observation: {observation}\")\n",
    "\n",
    "    qs = agent.infer_states(observation)\n",
    "    print(f\"inferred state: {np.argmax(qs[0])}\")\n",
    "\n",
    "    q_pi, G = agent.infer_policies()\n",
    "    print(\"inferred policies\")\n",
    "    next_action = agent.sample_action()\n",
    "    next_action = int(next_action[0])\n",
    "    print(f\"next_action: {location_action_names[next_action]}\")\n",
    "    location_observation = env.step(next_action)\n",
    "    is_slippery = t > 3 and t % 4 == 0\n",
    "    if is_slippery:\n",
    "        print(\"Slipping!\")\n",
    "        # replay the action to slip in the same direction\n",
    "        location_observation = env.step(next_action)\n",
    "    is_foggy = t > 3 and t % 4 == 1\n",
    "    if is_foggy:\n",
    "        print(\"Fog!\")\n",
    "        location_observation = apply_foggy_location(location_observation)\n",
    "    \n",
    "    print(f\"location_observation: {location_observation}\")\n",
    "    score_observation = score_from_location(location_observation)\n",
    "    print(f\"score_observation: {score_observation}\")\n",
    "    observation = [location_observation, score_observation]\n",
    "\n",
    "    \n",
    "    plot_grid(grid_width, grid_height, location_observation)\n",
    "\n",
    "    # if t > 0:\n",
    "    agent.beta_omega, agent.beta_omega_prior = agent.update_omega()\n",
    "    agent.beta_zeta, agent.beta_zeta_prior = agent.update_zeta(observation)\n",
    "    print(f\"Omega means: {np.mean(agent.beta_omega[0])} {np.mean(agent.beta_omega[1])}\")\n",
    "    print(f\"Zeta means: {np.mean(agent.beta_zeta[0])} {np.mean(agent.beta_zeta[1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.beta_omega"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.beta_omega_prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.beta_omega_prior[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.q_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
